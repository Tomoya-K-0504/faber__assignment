{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import MeCab\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing import sequence\n",
    "import collections\n",
    "\n",
    "# import gensim.parsing.preprocessing\n",
    "from gensim import corpora, matutils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DIC_NAME = 'dic_raw_full4.txt'\n",
    "\n",
    "def load_json(data_dir):\n",
    "    with open(os.path.join(data_dir, 'livedoor.json')) as f:\n",
    "        items = json.load(f)\n",
    "    return items\n",
    "\n",
    "def clean_text(text):\n",
    "    replaced_text = '\\n'.join(s.strip() for s in text.splitlines()[2:] if s != '')  # skip header by [2:]\n",
    "    replaced_text = replaced_text.lower()\n",
    "    replaced_text = re.sub(r'[【】]', ' ', replaced_text)       # 【】の除去\n",
    "    replaced_text = re.sub(r'[（）()]', ' ', replaced_text)     # （）の除去\n",
    "    replaced_text = re.sub(r'[［］\\[\\]]', ' ', replaced_text)   # ［］の除去\n",
    "    replaced_text = re.sub(r'[@＠]\\w+', '', replaced_text)  # メンションの除去\n",
    "    replaced_text = re.sub(r'https?:\\/\\/.*?[\\r\\n ]', '', replaced_text)  # URLの除去\n",
    "    replaced_text = re.sub(r'　', ' ', replaced_text)  # 全角空白の除去\n",
    "    return replaced_text\n",
    "\n",
    "def tokenize(text):\n",
    "    mecabTagger = MeCab.Tagger('mecal-ipadic-neologd')\n",
    "    word_list = []\n",
    "    res = mecabTagger.parseToNode(text)\n",
    "    while res:\n",
    "        pos = res.feature.split(\",\")\n",
    "        if pos[0] in [\"名詞\"]:\n",
    "            if not pos[1] in [\"代名詞\", \"固有名詞\", \"数\", \"非自立\", \"特殊\"]:\n",
    "                try:\n",
    "                    word_list.append(res.surface)\n",
    "                except UnicodeDecodeError:\n",
    "                    print('デコードエラー→'+pos[0]+pos[1]+pos[2])\n",
    "        res = res.next\n",
    "    return word_list\n",
    "\n",
    "def make_words_list(data):\n",
    "    words_list = [clean_text(text) for text in data]\n",
    "    words_list = [tokenize(text) for text in words_list]\n",
    "    return words_list\n",
    "\n",
    "def load_dic(project_dir, data, words_list):\n",
    "    DIC_DIR = os.path.join(project_dir, 'dic', DIC_NAME)\n",
    "    if not os.path.exists(DIC_DIR):\n",
    "        dictionary = corpora.Dictionary(words_list)\n",
    "        dictionary.filter_extremes(no_below=2, no_above=0.8)\n",
    "        dictionary.save_as_text(DIC_DIR)\n",
    "    dic = corpora.Dictionary.load_from_text(DIC_DIR)\n",
    "    return dic\n",
    "\n",
    "def make_data_set(words_list, dic):\n",
    "    # 辞書の次元→ len(dic.keys()) or len(dic.values())\n",
    "    vecs = [dic.doc2bow(word_list) for word_list in words_list]\n",
    "    x = [matutils.corpus2dense([vec], num_terms=len(dic)).T[0] for vec in vecs]\n",
    "    y = items['label']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8)\n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "    return x_train, x_test, y_train, y_test, x\n",
    "\n",
    "def make_model(input_dim, output_dim):\n",
    "    # set parameters:\n",
    "    first_hidden=400\n",
    "    second_hidden=200\n",
    "    third_hidden=100\n",
    "    fourth_hidden=50\n",
    "\n",
    "    # print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(Dense(first_hidden, input_dim=input_dim,  activation=\"relu\"))\n",
    "    model.add(Dense(second_hidden, input_dim=first_hidden,  activation=\"relu\"))\n",
    "    model.add(Dense(third_hidden, input_dim=second_hidden,  activation=\"relu\"))\n",
    "    model.add(Dense(fourth_hidden, input_dim=third_hidden,  activation=\"relu\"))\n",
    "    model.add(Dense(output_dim, input_dim=fourth_hidden,  activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "def load_model(input_dim, output_dim):\n",
    "    model_path = os.path.join(project_dir, 'model/model_json1.json')\n",
    "    if not os.path.exists(model_path):\n",
    "        print('made {0}'.format(model_path))\n",
    "        model = make_model(input_dim, output_dim)\n",
    "        with open(model_path, 'w') as f:\n",
    "            json.dump(model.to_json(), f)\n",
    "    else:\n",
    "        with open(model_path, 'r') as f:\n",
    "            try:\n",
    "                json_string = json.load(f)\n",
    "                model = model_from_json(json_string)\n",
    "                print('loaded from {0}'.format(model_path))\n",
    "            except UnicodeDecodeError:\n",
    "                model = make_model(input_dim, output_dim)\n",
    "                print('made {0}/{1}.'.format(model_path.split('/')[-2], model_path.split('/')[-1]))\n",
    "    return model, model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.livedoor.com/article/detail/4778030/\n",
      "2010-05-22T14:30:00+0900\n",
      "友人代表のスピーチ、独女はどうこなしている？\n",
      "　もうすぐジューン・ブライドと呼ばれる６月。独女の中には自分の式はまだなのに呼ばれてばかり……という「お祝い貧乏」状態の人も多いのではないだろうか？　さらに出席回数を重ねていくと、こんなお願いごとをされることも少なくない。\n",
      "\n",
      "　「お願いがあるんだけど……友人代表のスピーチ、やってくれないかな？」\n",
      "\n",
      "　さてそんなとき、独女はどう対応したらいいか？\n",
      "\n",
      "　最近だとインターネット等で検索すれば友人代表スピーチ用の例文サイトがたくさん出てくるので、それらを参考にすれば、無難なものは誰でも作成できる。しかし由利さん（33歳）はネットを参考にして作成したものの「これで本当にいいのか不安でした。一人暮らしなので聞かせて感想をいってくれる人もいないし、かといって他の友人にわざわざ聞かせるのもどうかと思うし……」ということで活用したのが、なんとインターネットの悩み相談サイトに。そこに作成したスピーチ文を掲載し「これで大丈夫か添削してください」とメッセージを送ったというのである。\n",
      "\n",
      "　「一晩で3人位の人が添削してくれましたよ。ちなみに自分以外にもそういう人はたくさんいて、その相談サイトには同じように添削をお願いする投稿がいっぱいありました」（由利さん）。ためしに教えてもらったそのサイトをみてみると、確かに「結婚式のスピーチの添削お願いします」という投稿が1000件を超えるくらいあった。めでたい結婚式の影でこんなネットコミュニティがあったとは知らなかった。\n",
      "\n",
      "　しかし「事前にお願いされるスピーチなら準備ができるしまだいいですよ。一番嫌なのは何といってもサプライズスピーチ！」と語るのは昨年だけで10万以上お祝いにかかったというお祝い貧乏独女の薫さん（35歳）\n",
      "\n",
      "　「私は基本的に人前で話すのが苦手なんですよ。だからいきなり指名されるとしどろもどろになって何もいえなくなる。そうすると自己嫌悪に陥って終わった後でもまったく楽しめなくなりますね」\n",
      "　\n",
      "　サプライズスピーチのメリットとしては、準備していない状態なので、フランクな本音をしゃべってもらえるという楽しさがあるようだ。しかしそれも上手に対応できる人ならいいが、苦手な人の場合だと「フランク」ではなく「しどろもどろ」になる危険性大。ちなみにプロの司会者の場合、本当のサプライズではなく式の最中に「のちほどサプライズスピーチとしてご指名させていただきます」という一言があることも多いようだが、薫さん曰く「そんな何分前に言われても無理！」らしい。要は「サプライズを楽しめる」というタイプの人選が大切ということか。\n",
      "\n",
      "　一方「ありきたりじゃつまらないし、ネットで例文を検索している際に『こんな方法もあるのか！』って思って取り入れました」という幸恵さん（30歳）が行ったスピーチは「手紙形式のスピーチ」というもの。\n",
      "\n",
      "　「○○ちゃんへ　みたいな感じで新婦の友人にお手紙を書いて読み上げるやり方です。これなら多少フランクな書き方でも大丈夫だし、何より暗記しないで堂々と読み上げることができますよね。読んだものはそのまま友人にあげれば一応記念にもなります」（幸恵さん）\n",
      "なるほど、確かにこれなら読みあげればいいだけなので、人前で話すのが苦手な人でも失敗しないかもしれない。\n",
      "\n",
      "　主役はあくまで新郎新婦ながらも、いざとなると緊張し、内容もあれこれ考えて、こっそりリハーサル……そんな人知れず頑張るスピーチ担当独女たちにも幸あれ（高山惠）\n",
      "\n",
      "デコードエラー→名詞一般*\n",
      "デコードエラー→名詞一般*\n",
      "デコードエラー→名詞一般*\n",
      "デコードエラー→名詞形容動詞語幹*\n"
     ]
    }
   ],
   "source": [
    "project_dir = os.getcwd()\n",
    "DATA_DIR = os.path.join(project_dir, 'data/processed')\n",
    "items = load_json(DATA_DIR)\n",
    "words_list = make_words_list(items['data'])\n",
    "dic = load_dic(project_dir, items['data'], words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made model/model_json1.json.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 400)               8008800   \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 9)                 459       \n",
      "=================================================================\n",
      "Total params: 8,114,609\n",
      "Trainable params: 8,114,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "5893/5893 [==============================] - 21s 4ms/step - loss: 0.6873 - acc: 0.8013\n",
      "Epoch 2/200\n",
      "5893/5893 [==============================] - 16s 3ms/step - loss: 0.0795 - acc: 0.9818\n",
      "Epoch 3/200\n",
      "5893/5893 [==============================] - 17s 3ms/step - loss: 0.0151 - acc: 0.9969\n",
      "Epoch 4/200\n",
      "5893/5893 [==============================] - 17s 3ms/step - loss: 0.0089 - acc: 0.9988\n",
      "Epoch 5/200\n",
      "5893/5893 [==============================] - 12s 2ms/step - loss: 0.0117 - acc: 0.9978\n",
      "Epoch 6/200\n",
      "5893/5893 [==============================] - 15s 3ms/step - loss: 0.0075 - acc: 0.9992\n",
      "Epoch 7/200\n",
      "5893/5893 [==============================] - 12s 2ms/step - loss: 0.0120 - acc: 0.9978\n",
      "Epoch 8/200\n",
      "5893/5893 [==============================] - 16s 3ms/step - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 9/200\n",
      "5893/5893 [==============================] - 13s 2ms/step - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 10/200\n",
      "5893/5893 [==============================] - 13s 2ms/step - loss: 0.0064 - acc: 0.9990\n",
      "Epoch 11/200\n",
      "5893/5893 [==============================] - 13s 2ms/step - loss: 0.0045 - acc: 0.9995\n",
      "Epoch 12/200\n",
      "5893/5893 [==============================] - 12s 2ms/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 13/200\n",
      "5893/5893 [==============================] - 12s 2ms/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12169bf60>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, x = make_data_set(words_list, dic)\n",
    "model, model_path = load_model(input_dim=len(x_train[0]), output_dim=len(y_train[0]))\n",
    "model.summary()\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='acc', verbose=1, patience=5, mode='auto')\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(model_path, monitor='acc', save_best_only=True, mode='auto', period=1)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=128, callbacks=[earlystopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1474/1474 [==============================] - 2s 1ms/step\n",
      "acc: 92.06%\n",
      "category 0 (dokujo-tsushin) has 178 items\n",
      "category 1 (it-life-hack) has 159 items\n",
      "category 2 (kaden-channel) has 176 items\n",
      "category 3 (livedoor-homme) has 105 items\n",
      "category 4 (movie-enter) has 178 items\n",
      "category 5 (peachy) has 155 items\n",
      "category 6 (smax) has 179 items\n",
      "category 7 (sports-watch) has 184 items\n",
      "category 8 (topic-news) has 160 items\n",
      "count 14  ==>  wrong predict : 3 , answer is 6\n",
      "count 36  ==>  wrong predict : 5 , answer is 0\n",
      "count 38  ==>  wrong predict : 0 , answer is 5\n",
      "count 47  ==>  wrong predict : 3 , answer is 5\n",
      "count 68  ==>  wrong predict : 4 , answer is 2\n",
      "count 70  ==>  wrong predict : 0 , answer is 5\n",
      "count 86  ==>  wrong predict : 5 , answer is 0\n",
      "count 103  ==>  wrong predict : 8 , answer is 5\n",
      "count 114  ==>  wrong predict : 2 , answer is 8\n",
      "count 117  ==>  wrong predict : 2 , answer is 3\n",
      "count 128  ==>  wrong predict : 7 , answer is 8\n",
      "count 145  ==>  wrong predict : 5 , answer is 0\n",
      "count 158  ==>  wrong predict : 4 , answer is 0\n",
      "count 169  ==>  wrong predict : 5 , answer is 1\n",
      "count 185  ==>  wrong predict : 4 , answer is 0\n",
      "count 193  ==>  wrong predict : 5 , answer is 0\n",
      "count 213  ==>  wrong predict : 2 , answer is 1\n",
      "count 217  ==>  wrong predict : 4 , answer is 0\n",
      "count 222  ==>  wrong predict : 5 , answer is 7\n",
      "count 232  ==>  wrong predict : 7 , answer is 8\n",
      "count 243  ==>  wrong predict : 0 , answer is 3\n",
      "count 245  ==>  wrong predict : 0 , answer is 3\n",
      "count 247  ==>  wrong predict : 0 , answer is 4\n",
      "count 254  ==>  wrong predict : 4 , answer is 5\n",
      "count 261  ==>  wrong predict : 5 , answer is 3\n",
      "count 266  ==>  wrong predict : 3 , answer is 7\n",
      "count 270  ==>  wrong predict : 3 , answer is 0\n",
      "count 289  ==>  wrong predict : 3 , answer is 4\n",
      "count 293  ==>  wrong predict : 0 , answer is 3\n",
      "count 302  ==>  wrong predict : 4 , answer is 0\n",
      "count 312  ==>  wrong predict : 4 , answer is 0\n",
      "count 316  ==>  wrong predict : 1 , answer is 3\n",
      "count 354  ==>  wrong predict : 0 , answer is 5\n",
      "count 355  ==>  wrong predict : 3 , answer is 5\n",
      "count 389  ==>  wrong predict : 8 , answer is 7\n",
      "count 396  ==>  wrong predict : 7 , answer is 8\n",
      "count 397  ==>  wrong predict : 3 , answer is 1\n",
      "count 411  ==>  wrong predict : 7 , answer is 8\n",
      "count 440  ==>  wrong predict : 7 , answer is 8\n",
      "count 444  ==>  wrong predict : 0 , answer is 3\n",
      "count 449  ==>  wrong predict : 2 , answer is 6\n",
      "count 450  ==>  wrong predict : 1 , answer is 2\n",
      "count 475  ==>  wrong predict : 5 , answer is 2\n",
      "count 483  ==>  wrong predict : 0 , answer is 5\n",
      "count 512  ==>  wrong predict : 4 , answer is 0\n",
      "count 532  ==>  wrong predict : 3 , answer is 1\n",
      "count 539  ==>  wrong predict : 7 , answer is 8\n",
      "count 541  ==>  wrong predict : 0 , answer is 5\n",
      "count 548  ==>  wrong predict : 3 , answer is 5\n",
      "count 549  ==>  wrong predict : 4 , answer is 5\n",
      "count 574  ==>  wrong predict : 4 , answer is 8\n",
      "count 622  ==>  wrong predict : 7 , answer is 5\n",
      "count 626  ==>  wrong predict : 8 , answer is 7\n",
      "count 640  ==>  wrong predict : 4 , answer is 5\n",
      "count 663  ==>  wrong predict : 5 , answer is 0\n",
      "count 676  ==>  wrong predict : 4 , answer is 3\n",
      "count 692  ==>  wrong predict : 4 , answer is 3\n",
      "count 701  ==>  wrong predict : 7 , answer is 1\n",
      "count 702  ==>  wrong predict : 3 , answer is 2\n",
      "count 704  ==>  wrong predict : 7 , answer is 8\n",
      "count 714  ==>  wrong predict : 5 , answer is 0\n",
      "count 724  ==>  wrong predict : 5 , answer is 0\n",
      "count 741  ==>  wrong predict : 3 , answer is 5\n",
      "count 753  ==>  wrong predict : 4 , answer is 1\n",
      "count 772  ==>  wrong predict : 3 , answer is 0\n",
      "count 782  ==>  wrong predict : 0 , answer is 5\n",
      "count 798  ==>  wrong predict : 0 , answer is 3\n",
      "count 832  ==>  wrong predict : 7 , answer is 8\n",
      "count 835  ==>  wrong predict : 5 , answer is 3\n",
      "count 836  ==>  wrong predict : 7 , answer is 5\n",
      "count 842  ==>  wrong predict : 6 , answer is 2\n",
      "count 859  ==>  wrong predict : 4 , answer is 3\n",
      "count 866  ==>  wrong predict : 0 , answer is 5\n",
      "count 870  ==>  wrong predict : 3 , answer is 1\n",
      "count 878  ==>  wrong predict : 3 , answer is 0\n",
      "count 929  ==>  wrong predict : 5 , answer is 0\n",
      "count 942  ==>  wrong predict : 1 , answer is 3\n",
      "count 962  ==>  wrong predict : 3 , answer is 1\n",
      "count 971  ==>  wrong predict : 0 , answer is 5\n",
      "count 976  ==>  wrong predict : 5 , answer is 3\n",
      "count 978  ==>  wrong predict : 6 , answer is 3\n",
      "count 1001  ==>  wrong predict : 4 , answer is 7\n",
      "count 1010  ==>  wrong predict : 7 , answer is 5\n",
      "count 1013  ==>  wrong predict : 5 , answer is 0\n",
      "count 1032  ==>  wrong predict : 1 , answer is 5\n",
      "count 1058  ==>  wrong predict : 5 , answer is 8\n",
      "count 1064  ==>  wrong predict : 0 , answer is 5\n",
      "count 1087  ==>  wrong predict : 8 , answer is 7\n",
      "count 1093  ==>  wrong predict : 5 , answer is 0\n",
      "count 1103  ==>  wrong predict : 8 , answer is 7\n",
      "count 1109  ==>  wrong predict : 6 , answer is 1\n",
      "count 1110  ==>  wrong predict : 0 , answer is 1\n",
      "count 1123  ==>  wrong predict : 4 , answer is 5\n",
      "count 1133  ==>  wrong predict : 5 , answer is 0\n",
      "count 1163  ==>  wrong predict : 3 , answer is 6\n",
      "count 1178  ==>  wrong predict : 2 , answer is 1\n",
      "count 1196  ==>  wrong predict : 1 , answer is 4\n",
      "count 1212  ==>  wrong predict : 3 , answer is 0\n",
      "count 1225  ==>  wrong predict : 8 , answer is 2\n",
      "count 1242  ==>  wrong predict : 2 , answer is 1\n",
      "count 1250  ==>  wrong predict : 0 , answer is 5\n",
      "count 1252  ==>  wrong predict : 1 , answer is 8\n",
      "count 1264  ==>  wrong predict : 1 , answer is 3\n",
      "count 1269  ==>  wrong predict : 3 , answer is 0\n",
      "count 1272  ==>  wrong predict : 5 , answer is 0\n",
      "count 1279  ==>  wrong predict : 4 , answer is 0\n",
      "count 1311  ==>  wrong predict : 3 , answer is 4\n",
      "count 1316  ==>  wrong predict : 5 , answer is 7\n",
      "count 1348  ==>  wrong predict : 3 , answer is 6\n",
      "count 1358  ==>  wrong predict : 3 , answer is 5\n",
      "count 1368  ==>  wrong predict : 0 , answer is 3\n",
      "count 1372  ==>  wrong predict : 1 , answer is 0\n",
      "count 1380  ==>  wrong predict : 3 , answer is 0\n",
      "count 1403  ==>  wrong predict : 2 , answer is 8\n",
      "count 1415  ==>  wrong predict : 4 , answer is 0\n",
      "count 1451  ==>  wrong predict : 4 , answer is 3\n",
      "count 1460  ==>  wrong predict : 3 , answer is 6\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
    "classes = model.predict_classes(x_test, batch_size=128)\n",
    "proba = model.predict_proba(x_test, batch_size=128)\n",
    "\n",
    "# 各ラベルの項目数をカウント\n",
    "count_list = collections.Counter(classes)\n",
    "for k in sorted(count_list.keys()):\n",
    "    print(\"category {0} ({1}) has {2} items\".format(k, items['label_names'][str(k)], count_list[k]))\n",
    "\n",
    "# 各ラベルにとって典型的なデータをそれぞれ表示\n",
    "counter1 = range(len(y_test[0]))\n",
    "counter2 = range(len(x[0]))\n",
    "typical_list = [(np.argmax(proba[:,j])) for j in range(len(y_test[0]))]\n",
    "print(typical_list)\n",
    "for index, count1 in zip(typical_list, counter1):\n",
    "    print(\"Most typical content in category {0} ({1}) is this below\".format(count1, items['label_names'][str(count1)]))\n",
    "    for each_x, count2 in zip(x, counter2):\n",
    "        if np.allclose(x_test[index], each_x):\n",
    "            print(items['data'][count2])\n",
    "            break\n",
    "\n",
    "# 間違ったラベルへの分類をしたデータを確認\n",
    "for i in range(len(y_test)):\n",
    "    itemindex = np.where(y_test[i] == 1)\n",
    "    if classes[i] != itemindex[0]:\n",
    "        print(\"count {0}  ==>  wrong predict : {1} , answer is {2}\".format(i, classes[i], itemindex[0][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
